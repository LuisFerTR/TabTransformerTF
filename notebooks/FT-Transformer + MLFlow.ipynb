{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/google/auth/crypt/_cryptography_rsa.py:22: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography (40.0) will be the last to support Python 3.6.\n",
      "  import cryptography.exceptions\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset\n",
    "\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/06 21:24:54 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/02/06 21:24:54 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2023/02/06 21:24:54 INFO mlflow.tracking.fluent: Experiment with name 'fraud' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='fraud', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow \n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.166828</td>\n",
       "      <td>-1</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>-1.331345</td>\n",
       "      <td>AA</td>\n",
       "      <td>769</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.888115</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>-1</td>\n",
       "      <td>144</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>-0.816224</td>\n",
       "      <td>AB</td>\n",
       "      <td>366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>31.798819</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>40</td>\n",
       "      <td>3.108549</td>\n",
       "      <td>-0.755728</td>\n",
       "      <td>AC</td>\n",
       "      <td>870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>4.728705</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>-1.205124</td>\n",
       "      <td>AB</td>\n",
       "      <td>810</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>2.047904</td>\n",
       "      <td>linux</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.596414</td>\n",
       "      <td>-1</td>\n",
       "      <td>218</td>\n",
       "      <td>50</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>-0.773276</td>\n",
       "      <td>AB</td>\n",
       "      <td>890</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.775225</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "0           1     0.9               0.166828                         -1   \n",
       "1           1     0.9               0.296286                         -1   \n",
       "2           1     0.9               0.044985                         -1   \n",
       "3           1     0.9               0.159511                         -1   \n",
       "4           1     0.9               0.596414                         -1   \n",
       "\n",
       "   current_address_months_count  customer_age  days_since_request  \\\n",
       "0                            88            50            0.020925   \n",
       "1                           144            50            0.005418   \n",
       "2                           132            40            3.108549   \n",
       "3                            22            50            0.019079   \n",
       "4                           218            50            0.004441   \n",
       "\n",
       "   intended_balcon_amount payment_type  zip_count_4w  ...  has_other_cards  \\\n",
       "0               -1.331345           AA           769  ...                0   \n",
       "1               -0.816224           AB           366  ...                0   \n",
       "2               -0.755728           AC           870  ...                0   \n",
       "3               -1.205124           AB           810  ...                1   \n",
       "4               -0.773276           AB           890  ...                0   \n",
       "\n",
       "   proposed_credit_limit  foreign_request    source  \\\n",
       "0                  500.0                0  INTERNET   \n",
       "1                 1500.0                0  INTERNET   \n",
       "2                  200.0                0  INTERNET   \n",
       "3                  200.0                0  INTERNET   \n",
       "4                 1500.0                0  INTERNET   \n",
       "\n",
       "   session_length_in_minutes  device_os  keep_alive_session  \\\n",
       "0                   3.888115    windows                   0   \n",
       "1                  31.798819    windows                   0   \n",
       "2                   4.728705      other                   0   \n",
       "3                   2.047904      linux                   0   \n",
       "4                   3.775225  macintosh                   1   \n",
       "\n",
       "   device_distinct_emails_8w device_fraud_count  month  \n",
       "0                          1                  0      7  \n",
       "1                          1                  0      7  \n",
       "2                          1                  0      7  \n",
       "3                          1                  0      7  \n",
       "4                          1                  0      7  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"fraud_bool\"\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"source\",\n",
    "    \"device_os\",\n",
    "]\n",
    "NUMERIC_FEATURES = [\n",
    "    \"income\",\n",
    "    \"name_email_similarity\",\n",
    "    \"prev_address_months_count\",\n",
    "    \"current_address_months_count\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_request\",\n",
    "    \"intended_balcon_amount\",\n",
    "    \"zip_count_4w\",\n",
    "    \"velocity_6h\",\n",
    "    \"velocity_24h\",\n",
    "    \"velocity_4w\",\n",
    "    \"bank_branch_count_8w\",\n",
    "    \"date_of_birth_distinct_emails_4w\",\n",
    "    \"credit_risk_score\",\n",
    "    \"email_is_free\",\n",
    "    \"phone_home_valid\",\n",
    "    \"phone_mobile_valid\",\n",
    "    \"bank_months_count\",\n",
    "    \"has_other_cards\",\n",
    "    \"proposed_credit_limit\",\n",
    "    \"foreign_request\",\n",
    "    \"session_length_in_minutes\",\n",
    "    \"keep_alive_session\",\n",
    "    \"device_distinct_emails_8w\",\n",
    "    \"month\",\n",
    "]\n",
    "\n",
    "FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (640000, 32)\n",
      "Validation dataset shape: (160000, 32)\n",
      "Test dataset shape: (200000, 32)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Validation dataset shape: {val_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "train_data.loc[:, NUMERIC_FEATURES] = sc.fit_transform(train_data[NUMERIC_FEATURES])\n",
    "val_data.loc[:, NUMERIC_FEATURES] = sc.transform(val_data[NUMERIC_FEATURES])\n",
    "test_data.loc[:, NUMERIC_FEATURES] = sc.transform(test_data[NUMERIC_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tabtransformertf/utils/preprocessing.py:21: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  dataset[key] = value[:, tf.newaxis]\n",
      "/usr/local/lib/python3.6/site-packages/tabtransformertf/utils/preprocessing.py:27: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  dataset[key] = value[:, tf.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# To TF Dataset\n",
    "train_dataset = df_to_dataset(train_data[FEATURES + [LABEL]], LABEL, shuffle=True)\n",
    "val_dataset = df_to_dataset(val_data[FEATURES + [LABEL]], LABEL, shuffle=False)  # No shuffle\n",
    "test_dataset = df_to_dataset(test_data[FEATURES], shuffle=False) # No target, no shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FT-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fttransformer(\n",
    "    params_to_log, params_to_skip, out_dim=1, out_activation=\"relu\"\n",
    "):\n",
    "    # Define encoder\n",
    "    ft_encoder = FTTransformerEncoder(\n",
    "        **params_to_log,\n",
    "        **params_to_skip\n",
    "    )\n",
    "    # Add prediction head to the encoder\n",
    "    ft_transformer = FTTransformer(\n",
    "        encoder=ft_encoder,\n",
    "        out_dim=out_dim,\n",
    "        out_activation=out_activation,\n",
    "    )\n",
    "\n",
    "    return ft_transformer\n",
    "\n",
    "\n",
    "def train_model(model, train_params, train_dataset, val_dataset):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=train_params[\"learning_rate\"],\n",
    "        weight_decay=train_params[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            \"output\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "            \"importances\": None,\n",
    "        },\n",
    "        metrics={\n",
    "            \"output\": [tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\")],\n",
    "            \"importances\": None,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    early = EarlyStopping(\n",
    "        monitor=\"val_output_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=train_params[\"early_stop_patience\"],\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    callback_list = [early]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=train_params[\"num_epochs\"],\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callback_list,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def fttransformer_mlflow_run(\n",
    "    name,\n",
    "    encoder_params,\n",
    "    train_params,\n",
    "    params_to_skip,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    "    y_test,\n",
    "):\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.set_tag(\"model_name\", \"FTTransformer\")\n",
    "        # Log the params\n",
    "        mlflow.log_params(encoder_params)\n",
    "        mlflow.log_params(train_params)\n",
    "        # Build and train\n",
    "        ft_transformer = build_fttransformer(\n",
    "            encoder_params,\n",
    "            params_to_skip,\n",
    "            out_dim=1,\n",
    "            out_activation=\"sigmoid\",\n",
    "        )\n",
    "        ft_transformer = train_model(\n",
    "            ft_transformer, train_params, train_dataset, val_dataset\n",
    "        )\n",
    "        # Evaluate\n",
    "        test_preds = ft_transformer.predict(test_dataset)\n",
    "        test_auc = average_precision_score(\n",
    "            y_test, test_preds[\"output\"].ravel()\n",
    "        )\n",
    "        mlflow.log_metric(\"test_prauc\", test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    learning_rate=0.001, weight_decay=0.00001, early_stop_patience=3, num_epochs=1000\n",
    ")\n",
    "\n",
    "params_to_skip = dict(\n",
    "    numerical_data=train_data[NUMERIC_FEATURES].values,\n",
    "    categorical_data=train_data[CATEGORICAL_FEATURES].values,\n",
    "    y=train_data[LABEL].values,\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=CATEGORICAL_FEATURES,\n",
    "    explainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_embeddings_params = dict(\n",
    "    numerical_embedding_type=\"linear\",\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='linear',\n",
    "    encoder_params=linear_embeddings_params,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_params_to_log = dict(\n",
    "    numerical_embedding_type='periodic',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='periodic',\n",
    "    encoder_params=periodic_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLE - Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleq_params_to_log = dict(\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    ")\n",
    "\n",
    "pleq_params_to_skip = params_to_skip.copy()\n",
    "pleq_params_to_skip['y'] = None\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_quantile',\n",
    "    encoder_params=pleq_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=pleq_params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLE - Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plet_params_to_log = dict(\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    task='classification',\n",
    "    ple_tree_params = {\n",
    "        \"min_samples_leaf\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_target',\n",
    "    encoder_params=plet_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:3065: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "train_data[CATEGORICAL_FEATURES] = train_data[CATEGORICAL_FEATURES].astype(\"category\")\n",
    "val_data[CATEGORICAL_FEATURES] = val_data[CATEGORICAL_FEATURES].astype(\"category\")\n",
    "test_data[CATEGORICAL_FEATURES] = test_data[CATEGORICAL_FEATURES].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LGBM\"):\n",
    "    params = {\n",
    "        \"min_child_samples\": 10,\n",
    "        \"colsample_bytree\": 0.2\n",
    "    }\n",
    "    mlflow.set_tag(\"model_name\", \"LGBM\")\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    lgbm = LGBMClassifier(n_estimators=100000, **params)\n",
    "    lgbm.fit(\n",
    "        train_data[FEATURES], \n",
    "        train_data[LABEL], \n",
    "        eval_set=[(val_data[FEATURES], val_data[LABEL])],\n",
    "        early_stopping_rounds=200,\n",
    "        categorical_feature=CATEGORICAL_FEATURES\n",
    "    )\n",
    "    test_preds = lgbm.predict_proba(test_data[FEATURES])\n",
    "    pr = average_precision_score(test_data[LABEL], test_preds[:, 1])\n",
    "    mlflow.log_metric(\"test_prauc\", pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run():\n",
    "        param = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"n_estimators\": 20000,\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100)\n",
    "         }\n",
    "\n",
    "        mlflow.log_params(param)\n",
    "        mlflow.set_tag(\"model_name\", \"LGBM\")\n",
    "\n",
    "        lgbm = LGBMClassifier(**param)  \n",
    "        lgbm.fit(\n",
    "            train_data[FEATURES], \n",
    "            train_data[LABEL], \n",
    "            eval_set=[(val_data[FEATURES], val_data[LABEL])],\n",
    "            early_stopping_rounds=200,\n",
    "            categorical_feature=CATEGORICAL_FEATURES\n",
    "        )\n",
    "        preds = lgbm.predict_proba(val_data[FEATURES])\n",
    "        pr = average_precision_score(val_data[LABEL], preds[:, 1])\n",
    "        mlflow.log_metric(\"val_prauc\", pr)\n",
    "\n",
    "        return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LGBM_tuned\"):\n",
    "    best_params = study.best_params\n",
    "    mlflow.set_tag(\"model_name\", \"LGBM\")\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    lgbm = LGBMClassifier(n_estimators=100000, **best_params)\n",
    "    lgbm.fit(\n",
    "        train_data[FEATURES], \n",
    "        train_data[LABEL], \n",
    "        eval_set=[(val_data[FEATURES], val_data[LABEL])],\n",
    "        early_stopping_rounds=200,\n",
    "        categorical_feature=CATEGORICAL_FEATURES\n",
    "    )\n",
    "    test_preds = lgbm.predict_proba(test_data[FEATURES])\n",
    "    pr = average_precision_score(test_data[LABEL], test_preds[:, 1])\n",
    "    mlflow.log_metric(\"test_prauc\", pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
